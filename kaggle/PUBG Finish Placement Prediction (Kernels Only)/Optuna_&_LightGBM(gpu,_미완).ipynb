{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optuna & LightGBM(gpu, 미완).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IV8WWZSyvJ5Wbev6HXfgrvz3I-PPFsFj",
      "authorship_tag": "ABX9TyPuO2h84DHFuDYWs9l1L1wy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0GFtw7pAK69"
      },
      "outputs": [],
      "source": [
        "# !git clone --recursive https://github.com/Microsoft/LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd LightGBM"
      ],
      "metadata": {
        "id": "Pv-pbdGkAQUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir build"
      ],
      "metadata": {
        "id": "-dVxgVskAQRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cmake -DUSE_GPU=1"
      ],
      "metadata": {
        "id": "Z1NtbZnxAQPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !make -j$(nproc)"
      ],
      "metadata": {
        "id": "XzFBrsoFAQM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !sudo apt-get -y install python-pip"
      ],
      "metadata": {
        "id": "0YRD6pvaAQKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !sudo -H pip install setuptools pandas numpy scipy sckit-learn -U"
      ],
      "metadata": {
        "id": "4QhxfEotAQHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/LightGBM/python-package/"
      ],
      "metadata": {
        "id": "4V_U7laSAQD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !sudo python setup.py install --precompile"
      ],
      "metadata": {
        "id": "02CqatjUAQBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install optuna"
      ],
      "metadata": {
        "id": "KZl4dM3MFxem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pickle5"
      ],
      "metadata": {
        "id": "LxsQLHI8JT-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "import pickle5 as pickle\n",
        "import optuna\n",
        "from optuna import Trial\n",
        "from optuna.samplers import TPESampler\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "nCqA0VokAP-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/kaggle/train.pkl', 'rb') as fh:\n",
        "    train = pickle.load(fh)"
      ],
      "metadata": {
        "id": "H0eQyLS0FoKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/kaggle/test.pkl', 'rb') as gh:\n",
        "    test = pickle.load(gh)"
      ],
      "metadata": {
        "id": "k1ROxj6wFoH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns.unique()"
      ],
      "metadata": {
        "id": "rSbL3iNVV3WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train['headshotrate'] = train['kills']/train['headshotKills']\n",
        "train['killStreakrate'] = train['killStreaks']/train['kills']\n",
        "train['healthitems'] = train['heals'] + train['boosts']\n",
        "train['totalDistance'] = train['rideDistance'] + train[\"walkDistance\"] + train[\"swimDistance\"]\n",
        "train['headshotKills_over_kills'] = train['headshotKills'] / train['kills']\n",
        "train['distance_over_weapons'] = train['totalDistance'] / train['weaponsAcquired']\n",
        "train['walkDistance_over_heals'] = train['walkDistance'] / train['heals']\n",
        "train['walkDistance_over_kills'] = train['walkDistance'] / train['kills']\n",
        "train['killsPerWalkDistance'] = train['kills'] / train['walkDistance']\n",
        "train[\"skill\"] = train[\"headshotKills\"] + train[\"roadKills\"]\n",
        "\n",
        "train[train == np.Inf] = np.NaN\n",
        "train[train == np.NINF] = np.NaN\n",
        "\n",
        "train.fillna(0, inplace=True)\n",
        "\n",
        "train = train.drop(['Id', 'groupId', 'matchId'], axis=1)"
      ],
      "metadata": {
        "id": "4rplEeOLFoFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matchType = train.matchType.unique()\n",
        "match_dict = {}\n",
        "for i, each in enumerate(matchType):\n",
        "    match_dict[each] = i\n",
        "train.matchType = train.matchType.map(match_dict)\n",
        "matchtype_test = test.matchType.unique()\n",
        "match_dict_test = {}\n",
        "for i, each in enumerate(matchtype_test):\n",
        "    match_dict_test[each] = i\n",
        "test.matchType = test.matchType.map(match_dict_test)\n"
      ],
      "metadata": {
        "id": "nhziWEfpLojo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "m5jjmEc5VfgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop('winPlacePerc', axis=1)\n",
        "y = train['winPlacePerc']"
      ],
      "metadata": {
        "id": "VsmyWM4VFoB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "ctITlR7AFn-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() \n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() \n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "\n",
        "X_train = reduce_mem_usage(X_train)\n",
        "X_test = reduce_mem_usage(X_test)"
      ],
      "metadata": {
        "id": "mO0u-zjKZcgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "RfaxPUv3RtHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "mm_sc = MinMaxScaler()\n",
        "mm_sc.fit(X_train)\n",
        "\n",
        "X_train_scaled = mm_sc.transform(X_train)\n",
        "X_test_scaled = mm_sc.transform(X_test)"
      ],
      "metadata": {
        "id": "qAYWyw1C1ZW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "linear = LinearRegression()\n",
        "linear.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "_xiO5hbO2PfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = linear.predict(X_test_scaled)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "d50UifDt2qI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)"
      ],
      "metadata": {
        "id": "kIuPCPqn2qFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('MSE:', mse)\n",
        "print('R Squared:', r2)\n",
        "print('MAE:', mae)"
      ],
      "metadata": {
        "id": "ZjWa3oSY2qCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from lightgbm.sklearn import LGBMRegressor\n",
        "\n",
        "# KFold(CV), partial : optuna를 사용하기 위함\n",
        "from sklearn.model_selection import KFold\n",
        "from functools import partial\n"
      ],
      "metadata": {
        "id": "FnsEifTaR9eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start=time.time()\n",
        "model = RandomForestRegressor(n_estimators=10, min_samples_leaf=5,\n",
        "                                max_features=0.5, n_jobs=-1, verbose=2)\n",
        "model.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "print(f\"{end - start:.5f} sec\")"
      ],
      "metadata": {
        "id": "egwmaFOyR9a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "evaluation_metric = r2_score\n",
        "\n",
        "print(\"Prediction\")\n",
        "pred_train = model.predict(X_train)\n",
        "pred_test = model.predict(X_test)\n",
        "\n",
        "\n",
        "train_score = evaluation_metric(y_train, pred_train)\n",
        "test_score = evaluation_metric(y_test, pred_test)\n",
        "\n",
        "print(\"Train Score : %.4f\" % train_score)\n",
        "print(\"Test Score : %.4f\" % test_score)"
      ],
      "metadata": {
        "id": "1qKekhBSSW2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Regression\n",
        "\n",
        "def optimizer(trial, X, y, K):\n",
        "    # 조절할 hyper-parameter 조합을 적어줍니다.\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 1000)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 8, 30)\n",
        "    max_features = trial.suggest_categorical(\"max_features\", ['auto', 'sqrt', 'log2'])\n",
        "    \n",
        "    \n",
        "    # 원하는 모델을 지정합니다, optuna는 시간이 오래걸리기 때문에 저는 보통 RF로 일단 테스트를 해본 뒤에 LGBM을 사용합니다.\n",
        "    model = RandomForestRegressor(n_estimators=n_estimators,\n",
        "                                  max_depth=max_depth,\n",
        "                                  max_features=max_features,\n",
        "                                  n_jobs=-1,\n",
        "                                  random_state=0xC0FFEE)\n",
        "    \n",
        "    \n",
        "    # K-Fold Cross validation을 구현합니다.\n",
        "    folds = KFold(n_splits=K)\n",
        "    scores = []\n",
        "    \n",
        "    for train_idx, val_idx in folds.split(X, y):\n",
        "        X_train = X.iloc[train_idx, :]\n",
        "        y_train = y.iloc[train_idx]\n",
        "        \n",
        "        X_val = X.iloc[val_idx, :]\n",
        "        y_val = y.iloc[val_idx]\n",
        "        \n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "        score = evaluation_metric(y_val, preds)\n",
        "        scores.append(score)\n",
        "    \n",
        "    \n",
        "    # K-Fold의 평균 loss값을 돌려줍니다.\n",
        "    return np.mean(scores)"
      ],
      "metadata": {
        "id": "j3aUtg3BSWsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "id": "7f47MSW1sy-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = 5 # Kfold 수\n",
        "opt_func = partial(optimizer, X=X_train, y=y_train, K=K)\n",
        "\n",
        "rf_study = optuna.create_study(study_name=\"RF\", direction=\"maximize\") # regression task에서 R^2를 최대화!\n",
        "rf_study.optimize(opt_func, n_trials=30)"
      ],
      "metadata": {
        "id": "_L1ThEu7SWpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_study.trials_dataframe()"
      ],
      "metadata": {
        "id": "8bD34MY5SWlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fsqSNNNRawBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=10)\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    lgbm_param = {\n",
        "        'objective': 'regression',\n",
        "        'verbose': -1,\n",
        "        'metric': 'mae', \n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 1024, step=1, log=True), \n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.7, 1.0),\n",
        "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0.0, 10.0),\n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "     }\n",
        "\n",
        "    # Generate model\n",
        "    model_lgbm = LGBMRegressor(**lgbm_param)\n",
        "    model_lgbm = model_lgbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], \n",
        "                                verbose=0, early_stopping_rounds=200)\n",
        "                           \n",
        "    # * 평기 지표이다.\n",
        "    # 원하는 평가 지표에 따라 사용하면 된다.                         \n",
        "    MAE = mean_absolute_error(y_test, model_lgbm.predict(X_test))\n",
        "    return MAE\n",
        "\n",
        "optuna_lgbm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "\n",
        "# * n_trials의 경우 optuna를 몇번 실행하여 hyper parameter를 찾을 것인지를 정한다.\n",
        "# 50으로 설정해도 유의미한 값이 나온다.\n",
        "optuna_lgbm.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "id": "3pNLGZT7K1NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_trial = optuna_lgbm.best_trial\n",
        "lgbm_trial_params = lgbm_trial.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(lgbm_trial.value, lgbm_trial_params))\n"
      ],
      "metadata": {
        "id": "NyadrICkK1FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm = LGBMRegressor(**lgbm_trial_params)\n",
        "lgbm_study = lgbm.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "CP88bijpK08C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}